Memo Tables and Uniqueness
--------------------------

So before subst node memo tables, which seem awfully expensive, I want to
implement uniqueness tracking.  Essentially we keep a flag on all nodes tracking
(approximately) whether there is more than one reference to it.  Most nodes will
be unique, with a few non-unique nodes.  Of course a subst memo table need only
memoize nonunique nodes, since unique ones are completely destroyed when
substituted.  I think that will significantly reduce how much memo table
overhead there is.  I want to implement uniqueness tracking and collect some
statistics about how many nodes are unique to test this hypothesis.

After uniqueness tracking is implemented, we could then GC unique nodes early.
If we keep a small object pool for "small" nodes (var, lambda, indir) (or heck
even all nodes and waste the extra space -- it's less than a factor of 2) then
we can collect the unique nodes back into the pool like reference counting
decreasing the number of copy GCs we need.  People say reference counting is
less efficient than copy GC but I find that hard to believe.  We need some
benchmarks, but might as well try it as long as we're going half way there
already.

I think basically every node is unique except for when a subst splits into both
branches of an apply.  So we need to change the subst algorithm to be a little
more eager, so that it can see the low-depth branch vanish immediately and
correctly track uniqueness of the target of the substitution.  The subst
algorithm can also be changed to immediately reuse unique body nodes instead of
allocating.

For memo table GC, we need some external data structure (C++ has a multimap),
storing "if X is alive, then it should go in (copied) memo tables M1,M2,..." .
I think that is enough, since when you copy the memo table you immediately copy
all the live keys, and then set up hooks for the not-yet discovered keys.

Unevaluation
------------

Looking at the heap resize test, it might be nice to allow a construct to
"de-share" something, to manually repeat work in the case that sharing would
take too much memory (which might also make it unique). Or do something really
cool like trying to detect whether to share using some time/space trade-off /
conal's "unevaluation".

The non-unique nodes seem like good candidates to unevaluate, the ones that will
stay around eating space after they are used (because in lazy code a node not
usually constructed until it is ready to be used for the first time). I'm
thinking something like, when a node has multiple references, keep an
unevaluated version of it around and measure the relative amount of work you put
into evaluating it.  Then when it's time to GC, if the evaluated subtree
(however you are supposed count that!) is dominated by its size rather than its
time, keep the unevaluated version instead.  That is very rough and I don't know
how doable that is in practice.

We can count the "partial size" of a rooted graph by counting the "uniquely
reachable subgraph", that is everything that is guaranteed to die if the root
dies.  So if we keep the unevaluated and evaluated forms of a non-unique node
next to each other (at the cost of only one node until the next GC), we can
measure the partial size of each and compare them.

Not quite!  What if there are non-unique nodes which are still in the uniquely
reachable subgraph; e.g. the graph is a DAG, but located entirely within the
subgraph. A full reference count would suffice to detect this.   Note, however,
that the inner non-unique node would be considering its own unevaluation.
Perhaps we can decide in some order, so that the inner one will have made its
decision by the time we consdier the outer...

Barring that nested case (which is an important case!), we can keep a recursive
count of the number of times the node was "entered" (including "goto REDO") to
get a sense of the amount of work put in -- return it from `reduce_whnf_rec`.
Then there is some parameter that relates bytes to reductions, and you make the
decision about which is more valuable at GC time.

Note that the more references there are to a node, the more valuable each
element of time work spent is (assuming that each reference will eventually
consume the node), whereas the space cost remains the same.  That is, more
references implies bigger caches for the same amount of work.

I'm currently thinking of implementing a "reference" node whose job is
essentially to have more than one thing pointing at it.  Every other node will
only have one unique reference.  These reference nodes can keep track of all
this sophisticated stuff, like the unevaluated version and the time counter.
Keeping multiply-referenced nodes separate might have consequences for the
whole algorithm and GC.

Reachability Counting
---------------------

It turns out that tracking the reachability set of a DAG is O(V^2) in general.
I have an algorithm which I think might work for this case though, again resting
on the assumption that the number of non-unique nodes is small.  Do a recursive
depth first search of the graph, returning a data structure with the following
information:

    * An integer indicating the amount of space that would be freed immeidately
      if the traversed link were removed.
    * A map from non-unique nodes to a pair:
        * The amount of space that would be freed if the key were collected
        * The number of total references to that node (so this must be known...)
        * The number of references to that node that we have found in this
          subgraph traversal

And whenever we traverse a node with multiple children, we add up the number of
references to each non-unique node that we have traversed.  If it's equal to the
total references, then this node "contains" the non-unique one, it can be
removed from the outgoing map and its space added to the outgoing space.

                    ROOT
                     | {3, <empty>}
                     x
      {0,a:{2,2,1}} ( ) {0,a:{2,2,1}}
                     a
      {0,b:{1,2,1}} ( ) {0,b:{1,2,1}}
                     b

This accounts for local dagness relatively efficiently.  If there are non-local
non-unique references it could get expensive.  I think most of those will be to
library functions.  Note that the above tracking is irrelevant for nodes whose
"space to be freed" is zero -- who cares?  And if something is directly
reachable from the root set, then it will not be freed, so you can have a
bazillion references to it and it won't clutter up these maps.

Explicit Sharing
----------------

Here is a passage I just found on page 64 of Thyer's paper...

> If details of which nodes are shared were to be maintained by using
> reference counting, and memo-tables only checked and updated for shared nodes,
> sharing would still be lost. 

which was like my whole thing.  He gives the example (translated)

    \a. let c = (a * a, a + a)
        in (c, snd c)

in which the `a+a` node will be marked as shared if `snd c` is reduced, and
not otherwise.

The notation I'm using to describe his graph though gives me an idea.  It seems
there is no need for memo tables in this way of stating it -- a single
substitution is created for `c`, which is precisely what we would have used a
memo table to share.  What if we have "share nodes" which occur at the lowest
common ancestor of the shared node.  Then we could ensure that substitution on
such nodes only happens once.

    power = \n x -> 
        let n' = n in 
        if n' == 0 
            then 1 
            else let x' = x in x' * power (n'-1) x'

    power 1 a
    = (x=a) (n=1) let n' = n in
                  if n' == 0
                     then 1
                     else let x' = x in x' * power (n'-1) x'
    = (x=a) let n' = (n=1) n in
            if n' == 0
               then 1
               else let x' = x in x' * power (n'-1) x'
    = let n' = (n=1) n in
      (x=a) if n' == 0
               then 1
               else let x' = x in x' * power (n'-1) x'
    = let n' = 1 in
      (x=a) if n' == 0
               then 1
               else let x' = x in x' * power (n'-1) x'
    -- We have reached a value (depth 0), so replace the let cell with 
    -- an indirection.
    = (x=a) if 1 == 0
               then 1
               else let x' = x in x' * power (1-1) x'
    = (x=a) let x' = x in x' * power (1-1) x'
    = let x' = (x=a) x in x' * power (1-1) x'
    -- If a was a let cell then we would replace x' with an indirection
    = let x' = a in x' * power (1-1) x'
    = let x' = a in
      x' * (x=x') (n=1-1) let n' = n in                              
                          if n' == 0                                 
                             then 1                                  
                             else let x' = x in x' * power (n'-1) x' 
    = let x' = a in
      x' * let n' = (n=1-1) n in 
           (x=x') if n' == 0
                     then 1
                     else let x'' = x in x'' * power (n-1) x''
    = let x' = a in
      x' * let n' = 0 in 
           (x=x') if n' == 0
                     then 1
                     else let x'' = x in x'' * power (n-1) x''
    = let x' = a in
      x' * (x=x') if 0 == 0
                     then 1
                     else let x'' = x in x'' * power (n-1) x''
    = let x' = a in
      x' * (x=x') 1
    = x' * 1

Yeah that's how it works.  I wasn't expecting the "indirection" points, 
but I think that might save me from my worries about let cells stacking up
and being worse than memo tables beacuse you have to traverse through them
each time you apply the function.  But we eliminate a let cell if the value
becomes depth 0 (a top level value which will never be substituted) or if it
already points to another let cell.  It's also interesting to note that a
substitution never branches -- you always substitute just one side of an
expression.  There may be interesting optimizations that leverage that.

Let's try Thyer's example:

    \a -> let c = let a' = a in (a' * a', a' + a')
          in (c, snd c)

No matter what we evaluate first, we should share the arithmetic operations.

    (a=2) let c = (a * a, a + a)
          in (c, snd c)
    let c = (a=2) (a * a, a + a)
          in (c, snd c)
    
It is clear that sharing will work.  

    (.) = \f g x -> f (g x)
    two = \f x -> let f' = f in f' (f' x)

    -- closed expressions need not be shared
    (two . two) a z
    = (.) two two a z
    = ((x=a) (g=two) (f=two) f (g x)) z
    = ((x=a) (g=two) two (g x)) z
    = ((x=a) (g=two) (f=g x) \x1 -> let f' = f in f' (f' x1)) z
    = (\x1 -> (x=a) (g=two) (f=g x) let f' = f in f' (f' x1)) z
    = (x1=z) (x=a) (g=two) (f=g x) let f' = f in f' (f' x1)
    = (x1=z) (x=a) (g=two) let f' = (f=g x) f in f' (f' x1)
    = (x1=z) (x=a) (g=two) let f' = g x in f' (f' x1)
    = (x1=z) (x=a) let f' = (g=two) g x in f' (f' x1)
    = (x1=z) (x=a) let f' = two x in f' (f' x1)
    = (x1=z) (x=a) let f' = (f=x) (\x2 -> let f'1 = f in f'1 (f'1 x2)) x in f' (f' x1)
    = (x1=z) (x=a) let f' = \x2 -> (f=x) let f'1 = f in f'1 (f'1 x2) in f' (f' x1)
    = (x1=z) (x=a) let f' = \x2 -> let f'1 = (f=x) f in f'1 (f'1 x2) in f' (f' x1)
    = (x1=z) (x=a) let f' = \x2 -> 
                        let f'1 = x in f'1 (f'1 x2)
                   in f' (f' x1)
    = (x1=z) (x=a) let b = let f'1 = x in f'1 (f'1 x2)
                   let f' = \x2 -> b
                   in (x2=f' x1) b

Observe how x2 is "technically" in scope since it will only be used under the
lambda, but it isn't really well-formed as a let.  I don't know if this is okay.
For example it might mean that b could simultaneously have multiple depths.

    = (x1=z) (x=a) let x3 = x
                   let b2 = f'1 (f'1 x2)
                   let b = let f'1 = x3 in b2
                   let f' = \x2 -> b
                   in let f'1 = x3 in (x2=f' x1) b2
    = (x1=z) (x=a) let x3 = x
                   let b2 = x3 (x3 x2)
                   let b = let f'1 = x3 in b2
                   let f' = \x2 -> b
                   in (x2=f' x1) b2
    = (x1=z) (x=a) let x3 = x
                   let b3 = x3 x2
                   let b2 = x3 b3
                   let b = let f'1 = x3 in b2
                   let f' = \x2 -> b
                   in x3 ((x2=f' x1) b3)
    = (x1=z) (x=a) let x3 = x
                   let b4 = x2
                   let b3 = x3 b4
                   let b2 = x3 b3
                   let b = let f'1 = x3 in b2
                   let f' = \x2 -> b
                   in x3 (x3 ((x2=f' x1) b4))
    = (x1=z) (x=a) let x3 = x
                   let b4 = x2
                   let b3 = x3 b4
                   let b2 = x3 b3
                   let b = let f'1 = x3 in b2
                   let f' = \x2 -> b
                   in x3 (x3 (f' x1))
    = (x1=z) let x3 = (x=a) x
             let b4 = x2
             let b3 = x3 b4
             let b2 = x3 b3
             let b = let f'1 = x3 in b2
             let f' = \x2 -> b
             in x3 (x3 (f' x1))
    = (x1=z) let x3 = a
             let b4 = x2
             let b3 = x3 b4
             let b2 = x3 b3
             let b = let f'1 = x3 in b2
             let f' = \x2 -> b
             in x3 (x3 (f' x1))
    = let x3 = a
      let b4 = x2
      let b3 = x3 b4
      let b2 = x3 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      in x3 (x3 (f' ((x1=z)x1)))

We can see that this is close to the normal form.   Suppose something continued
to force the function.

    = let x3 = a
      let b4 = x2
      let b3 = x3 b4
      let b2 = x3 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      in x3 (x3 ((x2=(x1=z)x1)b))

`f'` is collected by the garbage collector at least, and maybe earlier by
some amortized function compacter, or -- god forbid -- refcounts (which might
be able to elide the circular references problem because of explcit sharing,
somehow).

    = let x3 = a
      let b4 = x2
      let b3 = x3 b4
      let b2 = x3 b3
      in x3 (x3 ((x2=(x1=z)x1)b2))
    = let x3 = a
      let b4 = x2
      let b3 = x3 b4
      in x3 (x3 (x3 ((x2=(x1=z)x1)b3)))
    = let x3 = a
      let b4 = x2
      in x3 (x3 (x3 (x3 ((x2=(x1=z)x1)b4))))
    = let x3 = a
      in x3 (x3 (x3 (x3 ((x1=z)x1))))
    = let x3 = a
      in x3 (x3 (x3 (x3 z)))

So there are some interesting properties here.  It looks like my fears of these
cells essentially emulating memo tables are at least partially true.  We ended
up creating a let cell for each application in the shared expression.  I was
about to say but then they die out as things progress, but so do memo tables
because they are weak references.  I do not think this strategy is an
improvement.  :-(
