Memo Tables and Uniqueness
--------------------------

So before subst node memo tables, which seem awfully expensive, I want to
implement uniqueness tracking.  Essentially we keep a flag on all nodes tracking
(approximately) whether there is more than one reference to it.  Most nodes will
be unique, with a few non-unique nodes.  Of course a subst memo table need only
memoize nonunique nodes, since unique ones are completely destroyed when
substituted.  I think that will significantly reduce how much memo table
overhead there is.  I want to implement uniqueness tracking and collect some
statistics about how many nodes are unique to test this hypothesis.

After uniqueness tracking is implemented, we could then GC unique nodes early.
If we keep a small object pool for "small" nodes (var, lambda, indir) (or heck
even all nodes and waste the extra space -- it's less than a factor of 2) then
we can collect the unique nodes back into the pool like reference counting
decreasing the number of copy GCs we need.  People say reference counting is
less efficient than copy GC but I find that hard to believe.  We need some
benchmarks, but might as well try it as long as we're going half way there
already.

I think basically every node is unique except for when a subst splits into both
branches of an apply.  So we need to change the subst algorithm to be a little
more eager, so that it can see the low-depth branch vanish immediately and
correctly track uniqueness of the target of the substitution.  The subst
algorithm can also be changed to immediately reuse unique body nodes instead of
allocating.

For memo table GC, we need some external data structure (C++ has a multimap),
storing "if X is alive, then it should go in (copied) memo tables M1,M2,..." .
I think that is enough, since when you copy the memo table you immediately copy
all the live keys, and then set up hooks for the not-yet discovered keys.

Unevaluation
------------

Looking at the heap resize test, it might be nice to allow a construct to
"de-share" something, to manually repeat work in the case that sharing would
take too much memory (which might also make it unique). Or do something really
cool like trying to detect whether to share using some time/space trade-off /
conal's "unevaluation".

The non-unique nodes seem like good candidates to unevaluate, the ones that will
stay around eating space after they are used (because in lazy code a node not
usually constructed until it is ready to be used for the first time). I'm
thinking something like, when a node has multiple references, keep an
unevaluated version of it around and measure the relative amount of work you put
into evaluating it.  Then when it's time to GC, if the evaluated subtree
(however you are supposed count that!) is dominated by its size rather than its
time, keep the unevaluated version instead.  That is very rough and I don't know
how doable that is in practice.

We can count the "partial size" of a rooted graph by counting the "uniquely
reachable subgraph", that is everything that is guaranteed to die if the root
dies.  So if we keep the unevaluated and evaluated forms of a non-unique node
next to each other (at the cost of only one node until the next GC), we can
measure the partial size of each and compare them.

Not quite!  What if there are non-unique nodes which are still in the uniquely
reachable subgraph; e.g. the graph is a DAG, but located entirely within the
subgraph. A full reference count would suffice to detect this.   Note, however,
that the inner non-unique node would be considering its own unevaluation.
Perhaps we can decide in some order, so that the inner one will have made its
decision by the time we consdier the outer...

Barring that nested case (which is an important case!), we can keep a recursive
count of the number of times the node was "entered" (including "goto REDO") to
get a sense of the amount of work put in -- return it from `reduce_whnf_rec`.
Then there is some parameter that relates bytes to reductions, and you make the
decision about which is more valuable at GC time.

Note that the more references there are to a node, the more valuable each
element of time work spent is (assuming that each reference will eventually
consume the node), whereas the space cost remains the same.  That is, more
references implies bigger caches for the same amount of work.

I'm currently thinking of implementing a "reference" node whose job is
essentially to have more than one thing pointing at it.  Every other node will
only have one unique reference.  These reference nodes can keep track of all
this sophisticated stuff, like the unevaluated version and the time counter.
Keeping multiply-referenced nodes separate might have consequences for the
whole algorithm and GC.

Reachability Counting
---------------------

It turns out that tracking the reachability set of a DAG is O(V^2) in general.
I have an algorithm which I think might work for this case though, again resting
on the assumption that the number of non-unique nodes is small.  Do a recursive
depth first search of the graph, returning a data structure with the following
information:

    * An integer indicating the amount of space that would be freed immeidately
      if the traversed link were removed.
    * A map from non-unique nodes to a pair:
        * The amount of space that would be freed if the key were collected
        * The number of total references to that node (so this must be known...)
        * The number of references to that node that we have found in this
          subgraph traversal

And whenever we traverse a node with multiple children, we add up the number of
references to each non-unique node that we have traversed.  If it's equal to the
total references, then this node "contains" the non-unique one, it can be
removed from the outgoing map and its space added to the outgoing space.

                    ROOT
                     | {3, <empty>}
                     x
      {0,a:{2,2,1}} ( ) {0,a:{2,2,1}}
                     a
      {0,b:{1,2,1}} ( ) {0,b:{1,2,1}}
                     b

This accounts for local dagness relatively efficiently.  If there are non-local
non-unique references it could get expensive.  I think most of those will be to
library functions.  Note that the above tracking is irrelevant for nodes whose
"space to be freed" is zero -- who cares?  And if something is directly
reachable from the root set, then it will not be freed, so you can have a
bazillion references to it and it won't clutter up these maps.

Explicit Sharing
----------------

Here is a passage I just found on page 64 of [Thyer's paper][Thyer 1999]...

> If details of which nodes are shared were to be maintained by using
> reference counting, and memo-tables only checked and updated for shared nodes,
> sharing would still be lost. 

which was like my whole thing.  He gives the example (translated)

    \a. let c = (a * a, a + a)
        in (c, snd c)

in which the `a+a` node will be marked as shared if `snd c` is reduced, and
not otherwise.

The notation I'm using to describe his graph though gives me an idea.  It seems
there is no need for memo tables in this way of stating it -- a single
substitution is created for `c`, which is precisely what we would have used a
memo table to share.  What if we have "share nodes" which occur at the lowest
common ancestor of the shared node.  Then we could ensure that substitution on
such nodes only happens once.

    power = \n x -> 
        let n' = n in 
        if n' == 0 
            then 1 
            else let x' = x in x' * power (n'-1) x'

    power 1 a
    = (x=a) (n=1) let n' = n in
                  if n' == 0
                     then 1
                     else let x' = x in x' * power (n'-1) x'
    = (x=a) let n' = (n=1) n in
            if n' == 0
               then 1
               else let x' = x in x' * power (n'-1) x'
    = let n' = (n=1) n in
      (x=a) if n' == 0
               then 1
               else let x' = x in x' * power (n'-1) x'
    = let n' = 1 in
      (x=a) if n' == 0
               then 1
               else let x' = x in x' * power (n'-1) x'
    -- We have reached a value (depth 0), so replace the let cell with 
    -- an indirection.
    = (x=a) if 1 == 0
               then 1
               else let x' = x in x' * power (1-1) x'
    = (x=a) let x' = x in x' * power (1-1) x'
    = let x' = (x=a) x in x' * power (1-1) x'
    -- If a was a let cell then we would replace x' with an indirection
    = let x' = a in x' * power (1-1) x'
    = let x' = a in
      x' * (x=x') (n=1-1) let n' = n in                              
                          if n' == 0                                 
                             then 1                                  
                             else let x' = x in x' * power (n'-1) x' 
    = let x' = a in
      x' * let n' = (n=1-1) n in 
           (x=x') if n' == 0
                     then 1
                     else let x'' = x in x'' * power (n-1) x''
    = let x' = a in
      x' * let n' = 0 in 
           (x=x') if n' == 0
                     then 1
                     else let x'' = x in x'' * power (n-1) x''
    = let x' = a in
      x' * (x=x') if 0 == 0
                     then 1
                     else let x'' = x in x'' * power (n-1) x''
    = let x' = a in
      x' * (x=x') 1
    = x' * 1

Yeah that's how it works.  I wasn't expecting the "indirection" points, 
but I think that might save me from my worries about let cells stacking up
and being worse than memo tables beacuse you have to traverse through them
each time you apply the function.  But we eliminate a let cell if the value
becomes depth 0 (a top level value which will never be substituted) or if it
already points to another let cell.  It's also interesting to note that a
substitution never branches -- you always substitute just one side of an
expression.  There may be interesting optimizations that leverage that.

Let's try Thyer's example:

    \a -> let c = let a' = a in (a' * a', a' + a')
          in (c, snd c)

No matter what we evaluate first, we should share the arithmetic operations.

    (a=2) let c = (a * a, a + a)
          in (c, snd c)
    let c = (a=2) (a * a, a + a)
          in (c, snd c)

It is clear that sharing will work.  Let's try an example that has pathological
behavior with memo tables.

    (.) = \f g x -> f (g x)
    two = \f x -> let f' = f in f' (f' x)

    -- closed expressions need not be shared
    (two . two) a z
    = (.) two two a z
    = ((x=a) (g=two) (f=two) f (g x)) z
    = ((x=a) (g=two) two (g x)) z
    = ((x=a) (g=two) (f=g x) \x1 -> let f' = f in f' (f' x1)) z
    = (\x1 -> (x=a) (g=two) (f=g x) let f' = f in f' (f' x1)) z
    = (x1=z) (x=a) (g=two) (f=g x) let f' = f in f' (f' x1)
    = (x1=z) (x=a) (g=two) let f' = (f=g x) f in f' (f' x1)
    = (x1=z) (x=a) (g=two) let f' = g x in f' (f' x1)
    = (x1=z) (x=a) let f' = (g=two) g x in f' (f' x1)
    = (x1=z) (x=a) let f' = two x in f' (f' x1)
    = (x1=z) (x=a) let f' = (f=x) (\x2 -> let f'1 = f in f'1 (f'1 x2)) x in f' (f' x1)
    = (x1=z) (x=a) let f' = \x2 -> (f=x) let f'1 = f in f'1 (f'1 x2) in f' (f' x1)
    = (x1=z) (x=a) let f' = \x2 -> let f'1 = (f=x) f in f'1 (f'1 x2) in f' (f' x1)
    = (x1=z) (x=a) let f' = \x2 -> 
                        let f'1 = x in f'1 (f'1 x2)
                   in f' (f' x1)
    = (x1=z) (x=a) let b = let f'1 = x in f'1 (f'1 x2)
                   let f' = \x2 -> b
                   in (x2=f' x1) b

Observe how `x2` is "technically" in scope since it will only be used under the
lambda, but it isn't really well-formed as a let.  I don't know if this is okay.
For example it might mean that b could simultaneously have multiple depths. The
same things happens with f'1 in the next step, where it is allocated later than
it is used.  I'm thinking that these things might be represented by stack
offsets, so that would just mean it is function-like, depending on the value of
the stack.

    = (x1=z) (x=a) let x3 = x
                   let b2 = f'1 (f'1 x2)
                   let b = let f'1 = x3 in b2
                   let f' = \x2 -> b
                   let f'1 = x3 
                   in (x2=f' x1) b2

There is an opportunity to replace `f'1` with an indirection to `x3` straight
away but I am afraid it is not a valid move in general.  So I will leave it.

    = (x1=z) (x=a) let x3 = x
                   let b3 = f'1 x2
                   let b2 = f'1 b3
                   let b = let f'1 = x3 in b2
                   let f' = \x2 -> b
                   let f'1 = x3 
                   in x3 ((x2=f' x1) b3)
    = (x1=z) let x3 = (x=a) x
             let b3 = f'1 x2
             let b2 = f'1 b3
             let b = let f'1 = x3 in b2
             let f' = \x2 -> b
             let f'1 = x3 
             in x3 ((x2=f' x1) b3)
    = (x1=z) let x3 = a
             let b3 = f'1 x2
             let b2 = f'1 b3
             let b = let f'1 = x3 in b2
             let f' = \x2 -> b
             let f'1 = x3 
             in x3 ((x2=f' x1) b3)
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in (x1=z) x3 ((x2=f' x1) b3)
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in x3 ((x1=z) (x2=f' x1) b3)

And here it is in HNF.  It looks big but it also suggests a very compact
representation in which all (most?) the let cells are merged as one big table.
Copying it is a lot like copying "depth first" up to the point we get to the
expression, which ought to be easier for a computer.  Further, only `x3` and
`b3` have free variables, so we don't need to substitute into the others.  This
feels like it could be the power of this approach -- as we elaborate the
function body, we build up an optimized representation for future substitutions.
Let's keep evaluating until we get to NF.

    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in x3 ((x1=z) (x2=f' x1) b3)
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in x3 ((x1=z) f'1 ((x2=f' x1) x2))
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in x3 ((x1=z) x3 ((x2=f' x1) x2))
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in x3 (x3 ((x1=z) (x2=f' x1) x2))

I just pushed `x1` through `x3` because `x1` did not occur in `x3`.  I wonder
how I knew that, though.  Is depth tracking enough?

    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in x3 (x3 ((x1=z) f' x1))
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f' = \x2 -> b
      let f'1 = x3 
      in x3 (x3 ((x1=z) (x2=x1) b))

Garbage collect `f'`

    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f'1 = x3 
      in x3 (x3 ((x1=z) (x2=x1) b))
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f'1 = x3 
      in x3 (x3 ((x1=z) (x2=x1) b))

Here we have substituted `f'` again, which was our shared function argument.
We don't need to rebuild our "memo table", it's already been built.  

    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      let b = let f'1 = x3 in b2
      let f'1 = x3 
      in x3 (x3 ((x1=z) (x2=x1) let f'1 = x3 in b2))

Here we have rebound `f'1` while there was already an `f'1` in scope.  It's
bound to the same thing as before but it didn't necessarily have to be.  E.g. if
`x3` had been a free variable rather than referring to a higher cell.  So
there's some kind of stack business going on.

Note that `b` and the outer `f'1` are no longer used. So by the time the garbage
collector runs (or maybe we can do it automatically, not because of refcounting,
but because of linearity), it goes:

    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      in x3 (x3 ((x1=z) (x2=x1) let f'1 = x3 in b2))

There is an optimization opportunity when we see `(x1=z) (x2=x1)`; clearly this
should become `(x2=z`).  Again, we know there is only one reference to `x1` so
this is safe.  There was an opportunity earlier with `(x1=z) (x2=f' x1)`, maybe
we should always substitute into substitutions. 

    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      in x3 (x3 ((x2=z) let f'1 = x3 in b2))
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      in x3 (x3 (let f'1 = x3 in (x2=z) b2))
    = let x3 = a
      let b3 = f'1 x2
      let b2 = f'1 b3
      in x3 (x3 (let f'1 = x3 in (x2=z) b2))
    = let x3 = a
      let b3 = f'1 x2
      in x3 (x3 (let f'1 = x3 in (x2=z) f'1 b3))
    = let x3 = a
      let b3 = f'1 x2
      in x3 (x3 (let f'1 = x3 in (x2=z) x3 b3))
    = let x3 = a
      let b3 = f'1 x2
      in x3 (x3 (let f'1 = x3 in x3 ((x2=z) b3)))
    = let x3 = a
      let b3 = f'1 x2
      in x3 (x3 (let f'1 = x3 in x3 ((x2=z) b3)))
    = let x3 = a
      in x3 (x3 (let f'1 = x3 in x3 ((x2=z) f'1 x2)))
    = let x3 = a
      in x3 (x3 (x3 ((x2=z) x3 x2)))
    = let x3 = a
      in x3 (x3 (x3 (x3 (x2=z))))
    = let x3 = a
      in x3 (x3 (x3 (x3 z)))

And we get a perfect normal form, assuming the unused cells are properly
collected.  I'm thinking we could collect them eagerly by reference counting the
let cells -- we know all the other cells have refcount 1.

There are some interesting properties here.  At first it looked like I was just
recreating memo tables, but thinking about it more it doesn't seem like I am.
As the function is evaluated, we are building a "map" of how to substitute into
it efficiently.  For example, to *uniquely* substitute `a` out of the body we
arrived at is very cheap -- just substitute the let cell.  Substituting `z`
requires traversing the body.  I wonder why there is a difference.

However, if we *share* this expression and try to substitute it, it will be
inlined into the calling function.  The analog is that we don't create a memo
table when we are substituting into a non-shared function body.  That is
strange, I don't think that would work in the Thyer implementation (the body
might have DAGness).

I am excited for what this evaluation strategy is implying about representation.
It looks more like a traditional closure implementation -- the let cells play
the role of the environment.  As we reduce a function, we are dynamically
changing the shape of the environment table.  Environment entries with free
variables look like stack offset references.  I can imagine compiling this
to something much more efficient than Thyer's explicit graph representation.

The difference between this and e.g. the STG machine, where a large body can be
represented by a single code pointer that does all the work (is that what would
happen?) is that we need to later be prepared to inline that code.  Perhaps we
could keep both a "fast path" code reference and a "slow path" reference for
inlining.

Random thought: as we build the "local heap" of a function, if we store it as
a flat array, we will need to resize it as it grows.  We could locally garbage
collect at that moment, just like we do with the main heap,

------------------------------------------------------------------------------

In [Supercompilation by Evaluation][Bolingbroke 2010], they claim their strategy
can optimize

    let ones = 1 : ones in map (+1) ones

to

    let xs = 2 : xs in xs

and I would like to achieve a similar result at runtime.  I tried manual
evaluation of this in Thyer but made a few mistakes and didn't want to redo, but
I think Thyer does this. But my new explicit sharing form does not.

      let map = \f -> let f1 = f   -- f only occurs once syntactically , but it
                                   -- is used in a shared binding so it is 
                                   -- shared
                      let mapf = \xs -> case xs of
                                    [] -> []
                                    (a:b) -> f1 a : mapf b
                      in mapf
          ones = 1 : ones
      in map (+1) ones
    = let B = let f1 = f 
                  mapf = \xs -> case xs of [] -> []; (a:b) -> f1 a : mapf b 
               in mapf
          ones = 1 : ones
      in ((f=(+1)) B) ones
    = let ones = 1 : ones
      in ((f=(+1)) 
          let f2 = f
              mapf1 = \xs -> case xs of [] -> []; (a:b) -> f2 a : mapf1 b) 
         ones
    = let ones = 1 : ones
      in (let f2 = (f=(+1)) f
              mapf1 = \xs -> case xs of [] -> []; (a:b) -> f2 a : mapf1 b)
           in mapf1
         ones
    = let ones = 1 : ones
          f2 = (f=(+1)) f
          mapf1 = \xs -> case xs of [] -> []; (a:b) -> f2 a : mapf1 b
      in mapf1 ones

The following step is possibly problematic -- we duplicate the case when we
should have a chance to share it.  We could share by memoizing a substitution
between two shared nodes (i.e. a shared argument and a shared body).  Let's try
it.

    = let ones = 1 : ones
          f2 = (f=(+1)) f
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> f2 a : mapf1 b
      in (xs=ones) B1
    = let ones = 1 : ones
          f2 = (f=(+1)) f
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> f2 a : mapf1 b
          xs=ones_B1 = (xs=ones) B1
      in xs=ones_B1
    = let ones = 1 : ones
          f2 = (f=(+1)) f
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = f2 a : mapf1 b
          xs=ones_B1 = case 1:ones of [] -> []; (a:b) -> B2
      in xs=ones_B1
    = let ones = 1 : ones
          f2 = (f=(+1)) f
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = f2 a : mapf1 b
          xs=ones_B1 = (b=ones) (a=1) B2
      in xs=ones_B1
    = let ones = 1 : ones
          f2 = (f=(+1)) f
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = B5 : B6
          B3 = f2 a
          B4 = mapf1 b
          B5 = (a=1) B3
          B6 = (b=ones) B4
      in B5 : B6
    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : B6
          B3 = f2 a
          B4 = mapf1 b
          B6 = (b=ones) B4
      in 2 : B6
    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : b=ones_B4
          B3 = f2 a
          B4 = mapf1 b
          b=ones_B4 = (b=ones) B4
      in 2 : b=ones_B4
    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : b=ones_B4
          B3 = f2 a
          B4 = mapf1 b
          b=ones_B4 = (b=ones) (xs=b) B1
      in 2 : b=ones_B4

Here we substitute into the substitution.

    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : b=ones_B4
          B3 = f2 a
          B4 = mapf1 b
          b=ones_B4 = (xs=(b=ones) b) B1
      in 2 : b=ones_B4

We didn't memoize here because `(b=ones) b` is *not* a shared node.  I think
this is a problem.

    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : b=ones_B4
          B3 = f2 a
          B4 = mapf1 b
          b=ones_B4 = case (xs=(b=ones) b) of [] -> []; (a:b) -> B2
      in 2 : b=ones_B4
    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : b=ones_B4
          B3 = f2 a
          B4 = mapf1 b
          b=ones_B4 = case 1:ones of [] -> []; (a:b) -> B2
      in 2 : b=ones_B4
    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : b=ones_B4
          B3 = f2 a
          B4 = mapf1 b
          b=ones_B4 = (b=ones) (a=1) B2
      in 2 : b=ones_B4
    = let ones = 1 : ones
          f2 = (+1)
          mapf1 = \xs -> B1
          B1 = case xs of [] -> []; (a:b) -> B2
          B2 = B3 : B4
          xs=ones_B1 = 2 : b=ones_B4
          B3 = f2 a
          B4 = mapf1 b
          b=ones_B4 = ((a=1) B3) : ((b=ones) B4)
      in 2 : b=ones_B4
    = let f2 = (+1)
          B3 = f2 a
          b=ones_B4 = B7 : b=ones_B4
          B7 = (a=1) B3
      in 2 : b=ones_B4
    = let f2 = (+1)
          B3 = f2 a
          b=ones_B4 = B7 : b=ones_B4
          B7 = (a=1) B3
      in 2 : B7 : b=ones_B4
    = let b=ones_B4 = 2 : b=ones_B4
      in 2 : 2 : b=ones_B4

It worked.  It worked about one step later than it seems like it ought've.
That's pretty cool.  I did have to use memo tables, which is what I was trying
to get away from.  But we are only memoizing (potentially) shared nodes, which
is what I was trying to do in the first place with refcounting.

The key of this that is coming to light is using "local heaps" -- that is, when
we perform an allocation, we do so *within* the body of some function we are
reducing.  Then the next time the function is applied, we have those allocations
pre-performed and reduced and we just copy the results.

The other key is distinguishing shared and unshared nodes (seems like most nodes
want to be shared though), which allows us to create a map of where
substitutions should go -- a substitution only descends into one branch at a
time (which means, among other things, that we can substitute into other
substitutions directly).  The details of this map are yet unclear.

[Bolingbroke 2010]: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/supercomp-by-eval.pdf
[Thyer 1999]: http://thyer.name/phd-thesis/
